{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8dc0f29-dc52-4669-ac3b-2c27e971ce4a",
   "metadata": {},
   "source": [
    "# Find Mask shapes from Cellpose segmentation\n",
    "\n",
    "Author: Ryan Corbyn\n",
    "\n",
    "Date: 21/02/2023\n",
    "\n",
    "### Description: \n",
    "\n",
    "This is a script that can be used to find some shape descriptors for segemntation masks generated by the cellpose segmentation program. \n",
    "\n",
    "This script takes as inputs from the user: \n",
    "1. The file directory contianing the raw image files from an experiment in .TIF format. \n",
    "2. The cellpose segmentation masks as a .tif image stack file. (All the masks for each image are contained in a single .tif file)\n",
    "\n",
    "From these inputs, the program is able to extract the meta-data from the images in the folder, using the bioformats plugin, to determine the resolution of the image (pixel size) in microns. This is used later to determine the area and other size parameters of the segmentation masks. \n",
    "\n",
    "The btrack algorithm is used to generate the imaging tracks for the cell masks across all time points. The results of this can the be filtered so that only cells which have been identified for a minimum of, for example, 10 frames are seen as valid. The filtered results are saved into a variable called \"filtered_tracks\". \n",
    "\n",
    "The \"filtered_tracks\" variable is then used to identify each of the cell masks in the time sequence and the shape parameters for the masks calculated. The results of this analysis are then saved into a .csv file for the user. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0166e99c-fa81-483b-b59e-f84599ef77d7",
   "metadata": {},
   "source": [
    "## Import Dependancies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35423767-c0b0-4416-8d89-bc9a1252a592",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Import cellpose and other dependancies\n",
    "import btrack\n",
    "import napari\n",
    "\n",
    "# Import libraries for data analysis\n",
    "import numpy as np \n",
    "import aicsimageio\n",
    "import tifffile as tf\n",
    "from aicsimageio.readers.bioformats_reader import BioformatsReader\n",
    "import pandas as pd\n",
    "import os\n",
    "from skimage import measure\n",
    "\n",
    "# Import dependancies for user interface/input\n",
    "from tqdm import tqdm\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d69742c-83bd-4cd3-9ee3-5cef76c9686d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Select input folder containing the image dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "602635c1-7346-41d5-aaa4-2cd498dd0933",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # # Creates dialogue to ask directory\n",
    "# # # Get the folder containing the image stack. \n",
    "root = tk.Tk()\n",
    "root.withdraw() # Stops a second window opening\n",
    "SourceFolder = filedialog.askdirectory(title = 'Select Folder Containing images')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10755d08-97ba-4711-88bd-1b23cb427f93",
   "metadata": {},
   "source": [
    "## Choose the file containing the segmentation masks as a stack image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "676b3733-9186-4f8d-b03c-0b68bce6fc9c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 97, 2048, 2048)\n"
     ]
    }
   ],
   "source": [
    "# # # Creates dialogue to ask directory\n",
    "# # # Get the folder containing the image stack. \n",
    "root = tk.Tk()\n",
    "root.withdraw() # Stops a second window opening\n",
    "mask_file_name = filedialog.askopenfilename(title = 'Select Stack file')\n",
    "\n",
    "# # # # Get all .tif files in a folder. \n",
    "raw_masks = aicsimageio.imread(mask_file_name)\n",
    "np_masks = np.array(raw_masks)\n",
    "print(np_masks.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611e97a9-3058-40dc-98ae-35a0c85b640f",
   "metadata": {},
   "source": [
    "## Input the track length filter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6e36f40-c7b1-4bd1-8534-0100838c57de",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# select the minimum number of tracks \n",
    "min_tracks = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c7c3a8-4e77-4506-a5e6-c192232e73d2",
   "metadata": {},
   "source": [
    "#### Get all of the file names from a directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6acc752-abce-4866-bac7-7e2304df3c19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_image_file_names(folder_path): \n",
    "    '''Get all the file names for .tif files in a folder.'''\n",
    "    \n",
    "    list_of_files = []\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            if file[-4:] == '.jpg' or file[-4:] == '.tif' or file[-4:] == '.png' or file[-4:] == '.TIF':\n",
    "                list_of_files.append(os.path.join(file))\n",
    "                \n",
    "    return(list_of_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a32e92d-0f75-4f3a-81ca-ff29f5dbb274",
   "metadata": {},
   "source": [
    "#### Calculates the cell tracks from the segmentation mask stack file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0dd3eb0f-a210-40f8-9aa9-ee64e5c2878a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_Btracks(image_masks, configer_file, script_fold):\n",
    "    '''A method to find the tracks from the cellpose masks\n",
    "    generated from the image stack. \n",
    "    this method makes use of the trackpy package.'''\n",
    "    \n",
    "    FEATURES = [\n",
    "      \"area\",\n",
    "      \"major_axis_length\",\n",
    "      \"minor_axis_length\",\n",
    "       \"eccentricity\",\n",
    "      \"solidity\",\n",
    "                ]\n",
    "    \n",
    "    TRACKING_UPDATES = [\n",
    "      \"motion\",\n",
    "      \"visual\",\n",
    "            ]\n",
    "\n",
    "    objects = btrack.utils.segmentation_to_objects(image_masks, properties=tuple(FEATURES))\n",
    "    \n",
    "    with btrack.BayesianTracker() as tracker:\n",
    "        # configure the tracker using a config file\n",
    "        tracker.configure_from_file(configer_file)\n",
    "\n",
    "        tracker.features = FEATURES\n",
    "\n",
    "        # append the objects to be tracked\n",
    "        tracker.append(objects) \n",
    "\n",
    "        # set the volume (Z axis volume is set very large for 2D data)\n",
    "        tracker.volume=((0, 2000), (0, 2000), (-1e5, 1e5))\n",
    "\n",
    "        # track them (in interactive mode)\n",
    "        tracker.track(step_size=100)\n",
    "\n",
    "        # generate hypotheses and run the global optimizer\n",
    "        tracker.optimize()\n",
    "\n",
    "        # store the data in an HDF5 file\n",
    "        tracker.export(script_fold + '/tracks.h5', obj_type='obj_type_1')\n",
    "\n",
    "        # get the tracks as a python list\n",
    "        tracks = tracker.track(tracking_updates=TRACKING_UPDATES)\n",
    "\n",
    "        # get the data in a format for napari\n",
    "        data, properties, graph = tracker.to_napari(ndim=2)\n",
    "    \n",
    "    return(data, properties, graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea04113d-30f9-4b44-a0dc-335e50326a75",
   "metadata": {},
   "source": [
    "#### Filter the tracks by user defined track-length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26b0d72f-a577-4f41-8d4f-3ae19f160ce9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def filter_tracks(tracks, props, min_track_len, indicies):\n",
    "    '''Filter the tracks variable to only contain tracks longer than a \n",
    "    specified minimum (track_min). The resulting pandas array is then \n",
    "    sorted by object order.'''\n",
    "    \n",
    "    \n",
    "    filtered_tracks = pd.DataFrame()\n",
    "    filtered_props = pd.DataFrame()\n",
    "    \n",
    "    for i in range(indicies.shape[0]):\n",
    "        if indicies[i][1] - indicies[i][0] > min_track_len: \n",
    "            single_track = pd.DataFrame(tracks.iloc[indicies[i][0]: indicies[i][1]])\n",
    "            single_props = pd.DataFrame( props.iloc[indicies[i][0]: indicies[i][1]] )\n",
    "            \n",
    "            filtered_tracks = pd.concat([filtered_tracks, single_track], ignore_index = True)\n",
    "            filtered_props = pd.concat([filtered_props, single_props], ignore_index = True)\n",
    "        \n",
    "    return(filtered_tracks, filtered_props)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a039b461-8e70-44c5-b5bc-37f332d2eba1",
   "metadata": {},
   "source": [
    "#### Extract which of the tracks remain after filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "851903f7-94df-4ece-87e4-a55f51d02be2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def particle_index(tracks):\n",
    "    '''Find the indicies where the particle object in the \n",
    "    sorted_tracks variable changes. '''\n",
    "    \n",
    "    # Set the initial particle value\n",
    "    particle = tracks['Track'].iloc[0]\n",
    "    # generate the index_score variable. \n",
    "    index_score = [0]\n",
    "\n",
    "    # Loop to find the indicies in which the particle value changes. \n",
    "    for i in range(tracks.shape[0]):\n",
    "        if tracks['Track'].iloc[i] != particle:\n",
    "            index_score.append(i-1)\n",
    "            particle = tracks['Track'].iloc[i]\n",
    "            index_score.append(i)\n",
    "\n",
    "    # grab last i value. \n",
    "    index_score.append(i)\n",
    "    \n",
    "    # Convert index score to a 2D numpy array. \n",
    "    index_score = np.reshape(index_score, [int(len(index_score)/2), 2])\n",
    "    \n",
    "    return(index_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1930369c-d317-4072-a3e3-577aaed69dbd",
   "metadata": {},
   "source": [
    "#### Find the perimeter of the segmentation masks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61083bfb-cf2a-47ee-9783-b634949860dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_contours(image):\n",
    "    '''Use skimage to find the coutours (perimeter) of the cellpose masks.'''\n",
    "    \n",
    "    image[image < image_value] = 0\n",
    "    image[image > image_value] = 0\n",
    "\n",
    "    contours = measure.find_contours(image, 0.1)\n",
    "    contours = np.array(contours[0]).astype(int)\n",
    "        \n",
    "    return(contours)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337e10ac-4e32-4da4-b3bd-ac2b2c0ae1f9",
   "metadata": {},
   "source": [
    "#### Make sure the sub-image of a single mask is at least 2 pixels away from the boarder of the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dffb3339-7d25-4596-a0dc-6b6b990c715c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def correct_index(index_1, image_cropped): \n",
    "    '''Due to some weird calculation problems. I need to either subtrack or add 2 to the \n",
    "    dimensions of the sub-image in order to get a good measure of the perimeter of the\n",
    "    cell mask. \n",
    "    \n",
    "    This method makes sure that the indecies used to create the sub image has at least -/+ 2 \n",
    "    pixels between the cell mask and the image boudary. '''\n",
    "    \n",
    "    if index_1[0] == 1: \n",
    "        index_1[0] = 2\n",
    "    if index_1[1] == image_cropped.shape[0]-1:\n",
    "        index_1[1] = image_cropped.shape[0]-2\n",
    "    if index_1[2] == 1: \n",
    "        index_1[2] = 2\n",
    "    if index_1[3] == image_cropped.shape[1]-1:\n",
    "        index_1[3] = image_cropped.shape[1]-2\n",
    "        \n",
    "    return(index_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c414c4-14e3-4b66-867c-5579821d4a59",
   "metadata": {},
   "source": [
    "#### Calculate the major and minor axis of the segmentation mask. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d929d750-2de4-44ba-ae6e-a1491d488357",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_shape_values(contours): \n",
    "    '''Find the values for the major and minor axis of the cells \n",
    "    and the eccentricity of the mask.'''\n",
    "\n",
    "    half_contour_len = int( ( len(contours)-1 ) / 2 )\n",
    "    quart_leng = int (half_contour_len / 2)\n",
    "    max_dist = 0\n",
    "    min_dist = 0\n",
    "\n",
    "    for i in range(half_contour_len): \n",
    "        x_dist = np.power(contours[i, 1] -  contours[i + half_contour_len, 1], 2)\n",
    "        y_dist = np.power(contours[i, 0] -  contours[i + half_contour_len, 0], 2)\n",
    "\n",
    "        total_dist = np.sqrt( x_dist + y_dist ) \n",
    "\n",
    "        if total_dist > max_dist: \n",
    "            max_dist = total_dist \n",
    "            \n",
    "            a = i + quart_leng\n",
    "            b = (i + half_contour_len + quart_leng) % len(contour)\n",
    "            \n",
    "            x_min_dist = np.power(contours[a, 1] -  contours[b, 1], 2)\n",
    "            y_min_dist = np.power(contours[a, 0] -  contours[b, 0], 2)\n",
    "\n",
    "            min_dist = np.sqrt(x_min_dist + y_min_dist)\n",
    "    \n",
    "    dist = [min_dist, max_dist]\n",
    "    \n",
    "    return(np.max(dist), np.min(dist))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23467cc3-114a-48d8-8ae9-9585506778b5",
   "metadata": {},
   "source": [
    "### Extract image metadata  - Very important."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11f0e45e-7cf9-4015-9f6f-e1a17a107ba5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:/2023-01-31/plate1_p1 197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sburacco\\Anaconda3\\envs\\shape_env\\lib\\site-packages\\ome_types\\_convenience.py:106: FutureWarning: The default XML parser will be changing from 'xmlschema' to 'lxml' in version 0.4.0.  To silence this warning, please provide the `parser` argument, specifying either 'lxml' (to opt into the new behavior), or'xmlschema' (to retain the old behavior).\n",
      "  d = to_dict(os.fspath(xml), parser=parser, validate=validate)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Resolution = 1.0 microns per pixel\n",
      "Pixel Area = 1.0 microns squared\n"
     ]
    }
   ],
   "source": [
    "# Get all .tif files in a folder. \n",
    "file_list = get_image_file_names(SourceFolder)\n",
    "\n",
    "print(SourceFolder, len(file_list))\n",
    "\n",
    "# Extract all image matadata from an image in folder. \n",
    "meta_data = BioformatsReader(SourceFolder + '\\\\' + file_list[0])\n",
    "\n",
    "# Read pixel size from metadata. \n",
    "reader = BioformatsReader.physical_pixel_sizes.fget(meta_data)\n",
    "\n",
    "x_res = np.array(reader)[1]\n",
    "y_res = np.array(reader)[2]\n",
    "\n",
    "pixel_area = x_res * y_res\n",
    "\n",
    "print('Image Resolution = ' + str(x_res) + ' microns per pixel')\n",
    "print('Pixel Area = '+ str(np.round(pixel_area, 3)) + ' microns squared')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87d0fcd-16dc-4f77-8957-82d770a09274",
   "metadata": {},
   "source": [
    "#### Calculate the cell tracks from segmentation masks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e112a496-ab66-4093-ae2e-ab65bb8ecc92",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO][2023/06/15 03:08:47 PM] Localizing objects from segmentation...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 97, 2048, 2048)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO][2023/06/15 03:09:48 PM] Objects are of type: <class 'dict'>\n",
      "[INFO][2023/06/15 03:09:49 PM] ...Found 25214 objects in 97 frames.\n",
      "[INFO][2023/06/15 03:09:49 PM] Loaded btrack: C:\\Users\\sburacco\\Anaconda3\\envs\\shape_env\\lib\\site-packages\\btrack\\libs\\libtracker.DLL\n",
      "[INFO][2023/06/15 03:09:49 PM] btrack (v0.5.0) library imported\n",
      "[INFO][2023/06/15 03:09:49 PM] Starting BayesianTracker session\n",
      "[INFO][2023/06/15 03:09:49 PM] Loading configuration file: \\\\data.beatson.gla.ac.uk\\data\\SHARED\\BAIR_DOCS\\BAIR_Analysis_Scripts\\Jupyter_Notebooks\\Cell_segmentation_and_tracking\\cell_config.json\n",
      "[INFO][2023/06/15 03:09:59 PM] Ending BayesianTracker session\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '\\\\\\\\data.beatson.gla.ac.uk\\\\data\\\\SHARED\\\\BAIR_DOCS\\\\BAIR_Analysis_Scripts\\\\Jupyter_Notebooks\\\\Cell_segmentation_and_tracking\\\\cell_config.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m configer_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mdata.beatson.gla.ac.uk\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mSHARED\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mBAIR_DOCS\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mBAIR_Analysis_Scripts\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mJupyter_Notebooks\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mCell_segmentation_and_tracking\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mcell_config.json\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Find the tracks for the individual cells in the image stack. \u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m cell_tracks, properties, graph \u001b[38;5;241m=\u001b[39m \u001b[43mfind_Btracks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstack_masks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfiger_file\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[7], line 23\u001b[0m, in \u001b[0;36mfind_Btracks\u001b[1;34m(image_masks, configer_file)\u001b[0m\n\u001b[0;32m     19\u001b[0m objects \u001b[38;5;241m=\u001b[39m btrack\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39msegmentation_to_objects(image_masks, properties\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mtuple\u001b[39m(FEATURES))\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m btrack\u001b[38;5;241m.\u001b[39mBayesianTracker() \u001b[38;5;28;01mas\u001b[39;00m tracker:\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;66;03m# configure the tracker using a config file\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m     \u001b[43mtracker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfigure_from_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfiger_file\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     25\u001b[0m     tracker\u001b[38;5;241m.\u001b[39mfeatures \u001b[38;5;241m=\u001b[39m FEATURES\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;66;03m# append the objects to be tracked\u001b[39;00m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\shape_env\\lib\\site-packages\\btrack\\core.py:167\u001b[0m, in \u001b[0;36mBayesianTracker.configure_from_file\u001b[1;34m(self, filename)\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Configure the tracker from a configuration file. See `configure`.\"\"\"\u001b[39;00m\n\u001b[0;32m    163\u001b[0m warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis function will be deprecated. Use `.configure()` instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m,\n\u001b[0;32m    166\u001b[0m )\n\u001b[1;32m--> 167\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfigure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\shape_env\\lib\\site-packages\\btrack\\core.py:184\u001b[0m, in \u001b[0;36mBayesianTracker.configure\u001b[1;34m(self, configuration)\u001b[0m\n\u001b[0;32m    182\u001b[0m     configuration \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mTrackerConfig(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfiguration)\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(configuration, (\u001b[38;5;28mstr\u001b[39m, os\u001b[38;5;241m.\u001b[39mPathLike)):\n\u001b[1;32m--> 184\u001b[0m     configuration \u001b[38;5;241m=\u001b[39m \u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_config\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfiguration\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_config \u001b[38;5;241m=\u001b[39m configuration\n\u001b[0;32m    188\u001b[0m \u001b[38;5;66;03m# set all configuration options using setattr\u001b[39;00m\n",
      "File \u001b[1;32m~\\Anaconda3\\envs\\shape_env\\lib\\site-packages\\btrack\\config.py:134\u001b[0m, in \u001b[0;36mload_config\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m    131\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading configuration file: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    132\u001b[0m filename \u001b[38;5;241m=\u001b[39m Path(filename)\n\u001b[1;32m--> 134\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m json_file:\n\u001b[0;32m    135\u001b[0m     json_data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(json_file)\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrackerConfig\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m json_data:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '\\\\\\\\data.beatson.gla.ac.uk\\\\data\\\\SHARED\\\\BAIR_DOCS\\\\BAIR_Analysis_Scripts\\\\Jupyter_Notebooks\\\\Cell_segmentation_and_tracking\\\\cell_config.json'"
     ]
    }
   ],
   "source": [
    "stack_masks = np.array(raw_masks)\n",
    "print(stack_masks.shape)\n",
    "stack_masks = stack_masks[0, 0, :, :, :]\n",
    "\n",
    "script_folder = os.getcwd()\n",
    "configer_file = script_folder + '\\\\cell_config.json'\n",
    "\n",
    "# Find the tracks for the individual cells in the image stack. \n",
    "cell_tracks, properties, graph = find_Btracks(stack_masks, configer_file, script_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31b3144-ceb7-4db2-a452-e19f8f0a9bc6",
   "metadata": {},
   "source": [
    "### Filter the tracks according to user-defined minimum track length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fac97ffa-5043-41ba-8184-0db6c110348b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the tracks data into a pandas dataframe. \n",
    "data_arr = np.array(cell_tracks)\n",
    "df_data = pd.DataFrame({'Track': data_arr[:, 0].astype(int), 'Frame': data_arr[:, 1].astype(int), 'X_pos': data_arr[:, 2], 'Y_pos': data_arr[:, 3]})\n",
    "\n",
    "# Find the indicies which describe a change in the object track. \n",
    "index = particle_index(df_data)\n",
    "\n",
    "# Filter the tracks by the minimum track length. \n",
    "filtered_tracks, filtered_props = filter_tracks(df_data, pd.DataFrame(properties), min_tracks, index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbeb4d51-2779-4f14-a579-6615c61ad524",
   "metadata": {},
   "source": [
    "## Calculate the shape features for all masks in the filtered tracks list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9e0cda-af42-486d-8181-6ccd23edb0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise variable. \n",
    "track_shapes_pd = pd.DataFrame()\n",
    "\n",
    "# for all the frames contained in the filtered_tracks variable. \n",
    "for i in tqdm( range( len( filtered_tracks['Track'] ) ) ):\n",
    "    \n",
    "    # Extract the frame of interest. \n",
    "    image_to_analyse = np.array(stack_masks[filtered_tracks['Frame'][i], :, :])\n",
    "    \n",
    "    # Extract the [x,y] for the track central point (track point) . \n",
    "    y_loc = int(filtered_tracks['X_pos'][i])\n",
    "    x_loc = int(filtered_tracks['Y_pos'][i] )\n",
    "    \n",
    "    # Makle sure the track point is within the image boundry. \n",
    "    if x_loc > stack_masks.shape[2]: \n",
    "        x_loc = stack_masks.shape[2]-1\n",
    "    if y_loc > stack_masks.shape[1]:\n",
    "        y_loc = stack_masks.shape[1]-1\n",
    "    \n",
    "    # Find the pixel value at the track point.\n",
    "    image_value = image_to_analyse[ y_loc, x_loc ]\n",
    "    \n",
    "    # Ignore the analysis if the track point value is 0.\n",
    "    # This means the tracking has missed the cell mask. \n",
    "    if image_value == 0: \n",
    "        continue \n",
    "    else: \n",
    "        # Find all the values in the image with the same value as \n",
    "        # the track point. \n",
    "        find_mask = np.where(image_to_analyse == image_value)\n",
    "        \n",
    "        # Find the values needed to generate a square around the \n",
    "        # mask in question. \n",
    "        index = [np.min(find_mask[0]), np.max(find_mask[0]), \n",
    "                            np.min(find_mask[1]), np.max(find_mask[1])]\n",
    "\n",
    "        # If the cell mask is at the image boarder, ignore it. \n",
    "        if index[0] == 0 or index[2] == 0 or np.max(find_mask[0]) == image_to_analyse.shape[0] or np.max(find_mask[1]) == image_to_analyse.shape[1]:\n",
    "            continue \n",
    "\n",
    "        else: \n",
    "            # Correct the index value to allow 2 pixels between the \n",
    "            # cell mask and the image boarder. \n",
    "            # Needed to accurately find the perimeter of the cell mask. \n",
    "            index = correct_index(index, image_to_analyse)\n",
    "            \n",
    "            # Generate a sub image: a square around the mask in question. \n",
    "            sub_image = np.array(image_to_analyse[index[0]-2 : index[1]+2, index[2]-2 : index[3]+2])\n",
    "            \n",
    "            # Find the perimeter around the cell. \n",
    "            contour = get_contours(sub_image)\n",
    "            \n",
    "            # Find the area and perimeter of the cell mask in pixels. \n",
    "            area = len(find_mask[0])\n",
    "            perimeter = len(contour[:,0])\n",
    "            \n",
    "            # Find the major and minor axis of the cell mask. \n",
    "            # Needed to calculate eccentricity. \n",
    "            major_axis, minor_axis = find_shape_values(contour)\n",
    "            # Calcuate eccentricity. \n",
    "            eccent = np.sqrt(1 - (minor_axis / major_axis) )\n",
    "            \n",
    "            # Store all information into a dictionary. \n",
    "            cell_shape_dict = {'Track': [filtered_tracks['Track'][i]],\n",
    "                   'Frame': [filtered_tracks['Frame'][i]],\n",
    "                    'Mask Number': [image_value],\n",
    "                   'X_pos': [filtered_tracks['Y_pos'][i]], \n",
    "                   'Y_pos': [filtered_tracks['X_pos'][i]], \n",
    "                   'Area (microns Squared)': [area * pixel_area], \n",
    "                   'Perimeter (microns)': [perimeter * x_res], \n",
    "                   'Major Axis (microns)': [major_axis * x_res], \n",
    "                   'Minor Axis (microns)': [minor_axis * x_res], \n",
    "                   'eccentricity': [eccent]}\n",
    "            \n",
    "            # Convert dictionary to dataframe\n",
    "            temp_df = pd.DataFrame(cell_shape_dict)\n",
    "            \n",
    "            # Append all information into a local variable. \n",
    "            track_shapes_pd = pd.concat([track_shapes_pd, temp_df])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e84aef5-1643-48a4-b734-19a15ac03a6b",
   "metadata": {},
   "source": [
    "## Save the segmentation mask data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3496dc-a4c6-4fd4-96a6-558eaf389592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the folder path from the file containing \n",
    "# the segmentation mask stack.\n",
    "save_path = os.path.dirname(mask_file_name)\n",
    "\n",
    "# Save the analysis to the same folder as the segmentation mask file. \n",
    "track_shapes_pd.to_csv(save_path + '\\\\' + 'cellpose_mask_shape_analysis.csv',\n",
    "                       index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
