{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8dc0f29-dc52-4669-ac3b-2c27e971ce4a",
   "metadata": {},
   "source": [
    "# Find Mask shapes from Cellpose segmentation\n",
    "------\n",
    "Author: Ryan Corbyn  \n",
    "Date: 21/02/2023\n",
    "\n",
    "--------\n",
    "\n",
    "### Description: \n",
    "\n",
    "This is a script that can be used to find some shape descriptors for segmentation masks generated by the cellpose segmentation program. \n",
    "\n",
    "This script takes as inputs from the user: \n",
    "1. The stack image file generated by the program: 1_Cell_segmentation_and_tracking\n",
    "2. The cellpose segmentation masks as a .tif image stack file. (All the masks for each image are contained in a single .tif file)\n",
    "\n",
    "The btrack algorithm is used to generate the tracks for the cell masks across all time points. The results of this can the be filtered so that only cells which have been tracked for a minimum of, for example 10, frames are seen as valid. The filtered results are saved into a variable called \"filtered_tracks\". \n",
    "\n",
    "The \"filtered_tracks\" variable is then used to identify each of the cell masks in the time sequence and the shape parameters for the masks calculated. The results of this analysis are then saved into a .csv file for the user. \n",
    "\n",
    "------------\n",
    "\n",
    "### The user is required to input: \n",
    "1. The image resolution for the original image. \n",
    "2. The minimum track length. \n",
    "3. The file location of the time-lapse stack image. \n",
    "4. The file location of the cell-mask stack image. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0166e99c-fa81-483b-b59e-f84599ef77d7",
   "metadata": {},
   "source": [
    "## Cell 1\n",
    "-----\n",
    "### Import Dependancies\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35423767-c0b0-4416-8d89-bc9a1252a592",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Import cellpose and other dependancies\n",
    "import btrack\n",
    "\n",
    "# Import libraries for data analysis\n",
    "import numpy as np \n",
    "import tifffile as tf\n",
    "import pandas as pd\n",
    "import os\n",
    "from skimage import measure\n",
    "\n",
    "# Import dependancies for user interface/input\n",
    "from tqdm import tqdm\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23467cc3-114a-48d8-8ae9-9585506778b5",
   "metadata": {},
   "source": [
    "## Cell 2\n",
    "---\n",
    "### User inputs\n",
    "---\n",
    "\n",
    "In the following cell, the user needs to input: \n",
    "1) The resolution of the images to be analysed. \n",
    "2) The minimum track length for an object to be included in the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f535cf44-c949-4c7a-8559-590ea3a645ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Input the image resolution:\n",
    "image_resolution = 0.635 # microns per pixel. \n",
    "\n",
    "# select the minimum number of tracks that an object must be tracked for. \n",
    "min_tracks = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d69742c-83bd-4cd3-9ee3-5cef76c9686d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Cell 3\n",
    "----\n",
    "### Select input folder containing the image dataset\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "602635c1-7346-41d5-aaa4-2cd498dd0933",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # # Get the folder containing the image files. \n",
    "root = tk.Tk()\n",
    "root.attributes(\"-topmost\", True)\n",
    "root.withdraw() # Stops a second window opening\n",
    "\n",
    "# Select the file name. \n",
    "image_stack = filedialog.askopenfilename(title = 'Select Folder Containing images')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10755d08-97ba-4711-88bd-1b23cb427f93",
   "metadata": {},
   "source": [
    "## Cell 4\n",
    "---\n",
    "### Choose the file containing the segmentation masks as a stack image.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "676b3733-9186-4f8d-b03c-0b68bce6fc9c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 97, 1040, 1392)\n"
     ]
    }
   ],
   "source": [
    "# # # Creates dialogue to ask directory\n",
    "# # # Get the folder containing the image stack. \n",
    "root = tk.Tk()\n",
    "root.attributes(\"-topmost\", True)\n",
    "root.withdraw() # Stops a second window opening\n",
    "mask_file_name = filedialog.askopenfilename(title = 'Select Stack file')\n",
    "\n",
    "print(np_masks.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a32e92d-0f75-4f3a-81ca-ff29f5dbb274",
   "metadata": {},
   "source": [
    "## Cell 5 \n",
    "---\n",
    "### Calculates the cell tracks from the segmentation mask stack file.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0dd3eb0f-a210-40f8-9aa9-ee64e5c2878a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_Btracks(image_masks, configer_file, script_fold):\n",
    "    '''A method to find the tracks from the cellpose masks\n",
    "    generated from the image stack. \n",
    "    this method makes use of the trackpy package.'''\n",
    "    \n",
    "    FEATURES = [\n",
    "      \"area\",\n",
    "      \"major_axis_length\",\n",
    "      \"minor_axis_length\",\n",
    "       \"eccentricity\",\n",
    "      \"solidity\",\n",
    "                ]\n",
    "    \n",
    "    TRACKING_UPDATES = [\n",
    "      \"motion\",\n",
    "      \"visual\",\n",
    "            ]\n",
    "\n",
    "    objects = btrack.utils.segmentation_to_objects(image_masks, properties=tuple(FEATURES))\n",
    "    \n",
    "    with btrack.BayesianTracker() as tracker:\n",
    "        # configure the tracker using a config file\n",
    "        tracker.configure_from_file(configer_file)\n",
    "\n",
    "        tracker.features = FEATURES\n",
    "\n",
    "        # append the objects to be tracked\n",
    "        tracker.append(objects) \n",
    "\n",
    "        # set the volume (Z axis volume is set very large for 2D data)\n",
    "        tracker.volume=((0, 2000), (0, 2000), (-1e5, 1e5))\n",
    "\n",
    "        # track them (in interactive mode)\n",
    "        tracker.track(step_size=100)\n",
    "\n",
    "        # generate hypotheses and run the global optimizer\n",
    "        tracker.optimize()\n",
    "\n",
    "        # store the data in an HDF5 file\n",
    "        tracker.export(script_fold + '/tracks.h5', obj_type='obj_type_1')\n",
    "\n",
    "        # get the tracks as a python list\n",
    "        tracks = tracker.track(tracking_updates=TRACKING_UPDATES)\n",
    "\n",
    "        # get the data in a format for napari\n",
    "        data, properties, graph = tracker.to_napari(ndim=2)\n",
    "    \n",
    "    return(data, properties, graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea04113d-30f9-4b44-a0dc-335e50326a75",
   "metadata": {},
   "source": [
    "## Cell 6\n",
    "---\n",
    "### Filter the tracks by user defined track-length\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26b0d72f-a577-4f41-8d4f-3ae19f160ce9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def filter_tracks(tracks, props, min_track_len, indicies):\n",
    "    '''Filter the tracks variable to only contain tracks longer than a \n",
    "    specified minimum (track_min). The resulting pandas array is then \n",
    "    sorted by object order.'''\n",
    "    \n",
    "    \n",
    "    filtered_tracks = pd.DataFrame()\n",
    "    filtered_props = pd.DataFrame()\n",
    "    \n",
    "    for i in range(indicies.shape[0]):\n",
    "        if indicies[i][1] - indicies[i][0] > min_track_len: \n",
    "            single_track = pd.DataFrame(tracks.iloc[indicies[i][0]: indicies[i][1]])\n",
    "            single_props = pd.DataFrame( props.iloc[indicies[i][0]: indicies[i][1]] )\n",
    "            \n",
    "            filtered_tracks = pd.concat([filtered_tracks, single_track], ignore_index = True)\n",
    "            filtered_props = pd.concat([filtered_props, single_props], ignore_index = True)\n",
    "        \n",
    "    return(filtered_tracks, filtered_props)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a039b461-8e70-44c5-b5bc-37f332d2eba1",
   "metadata": {},
   "source": [
    "## Cell 7\n",
    "---\n",
    "### Extract which of the tracks remain after filtering\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "851903f7-94df-4ece-87e4-a55f51d02be2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def particle_index(tracks):\n",
    "    '''Find the indicies where the particle object in the \n",
    "    sorted_tracks variable changes. '''\n",
    "    \n",
    "    # Set the initial particle value\n",
    "    particle = tracks['Track'].iloc[0]\n",
    "    # generate the index_score variable. \n",
    "    index_score = [0]\n",
    "\n",
    "    # Loop to find the indicies in which the particle value changes. \n",
    "    for i in range(tracks.shape[0]):\n",
    "        if tracks['Track'].iloc[i] != particle:\n",
    "            index_score.append(i-1)\n",
    "            particle = tracks['Track'].iloc[i]\n",
    "            index_score.append(i)\n",
    "\n",
    "    # grab last i value. \n",
    "    index_score.append(i)\n",
    "    \n",
    "    # Convert index score to a 2D numpy array. \n",
    "    index_score = np.reshape(index_score, [int(len(index_score)/2), 2])\n",
    "    \n",
    "    return(index_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1930369c-d317-4072-a3e3-577aaed69dbd",
   "metadata": {},
   "source": [
    "## Cell 8\n",
    "---\n",
    "### Find the perimeter of the segmentation masks. \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "61083bfb-cf2a-47ee-9783-b634949860dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_contours(image):\n",
    "    '''Use skimage to find the coutours (perimeter) of the cellpose masks.'''\n",
    "    \n",
    "    image[image < image_value] = 0\n",
    "    image[image > image_value] = 0\n",
    "\n",
    "    contours = measure.find_contours(image, 0.1)\n",
    "    contours = np.array(contours[0]).astype(int)\n",
    "        \n",
    "    return(contours)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "337e10ac-4e32-4da4-b3bd-ac2b2c0ae1f9",
   "metadata": {},
   "source": [
    "## Cell 9\n",
    "---\n",
    "### Make sure the sub-image of a single mask is at least 2 pixels away from the boarder of the image\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dffb3339-7d25-4596-a0dc-6b6b990c715c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def correct_index(index_1, image_cropped): \n",
    "    '''Due to some weird calculation problems. I need to either subtrack or add 2 to the \n",
    "    dimensions of the sub-image in order to get a good measure of the perimeter of the\n",
    "    cell mask. \n",
    "    \n",
    "    This method makes sure that the indecies used to create the sub image has at least -/+ 2 \n",
    "    pixels between the cell mask and the image boudary. '''\n",
    "    \n",
    "    if index_1[0] == 1: \n",
    "        index_1[0] = 2\n",
    "    if index_1[1] == image_cropped.shape[0]-1:\n",
    "        index_1[1] = image_cropped.shape[0]-2\n",
    "    if index_1[2] == 1: \n",
    "        index_1[2] = 2\n",
    "    if index_1[3] == image_cropped.shape[1]-1:\n",
    "        index_1[3] = image_cropped.shape[1]-2\n",
    "        \n",
    "    return(index_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c414c4-14e3-4b66-867c-5579821d4a59",
   "metadata": {},
   "source": [
    "## Cell 10 \n",
    "---\n",
    "### Calculate the major and minor axis of the segmentation mask. \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d929d750-2de4-44ba-ae6e-a1491d488357",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_shape_values(contours): \n",
    "    '''Find the values for the major and minor axis of the cells \n",
    "    and the eccentricity of the mask.'''\n",
    "\n",
    "    half_contour_len = int( ( len(contours)-1 ) / 2 )\n",
    "    quart_leng = int (half_contour_len / 2)\n",
    "    max_dist = 0\n",
    "    min_dist = 0\n",
    "\n",
    "    for i in range(half_contour_len): \n",
    "        x_dist = np.power(contours[i, 1] -  contours[i + half_contour_len, 1], 2)\n",
    "        y_dist = np.power(contours[i, 0] -  contours[i + half_contour_len, 0], 2)\n",
    "\n",
    "        total_dist = np.sqrt( x_dist + y_dist ) \n",
    "\n",
    "        if total_dist > max_dist: \n",
    "            max_dist = total_dist \n",
    "            \n",
    "            a = i + quart_leng\n",
    "            b = (i + half_contour_len + quart_leng) % len(contour)\n",
    "            \n",
    "            x_min_dist = np.power(contours[a, 1] -  contours[b, 1], 2)\n",
    "            y_min_dist = np.power(contours[a, 0] -  contours[b, 0], 2)\n",
    "\n",
    "            min_dist = np.sqrt(x_min_dist + y_min_dist)\n",
    "    \n",
    "    dist = [min_dist, max_dist]\n",
    "    \n",
    "    return(np.max(dist), np.min(dist))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87d0fcd-16dc-4f77-8957-82d770a09274",
   "metadata": {},
   "source": [
    "## Cell 11\n",
    "----\n",
    "### Calculate the cell tracks from segmentation masks. \n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e112a496-ab66-4093-ae2e-ab65bb8ecc92",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO][2024/02/15 11:30:22 AM] Localizing objects from segmentation...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 97, 1040, 1392)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO][2024/02/15 11:30:41 AM] Objects are of type: <class 'dict'>\n",
      "[INFO][2024/02/15 11:30:41 AM] ...Found 4576 objects in 97 frames.\n",
      "[INFO][2024/02/15 11:30:41 AM] Loaded btrack: C:\\Users\\RCORBYN\\Anaconda3\\envs\\cellpose_and_tracking_gpu\\lib\\site-packages\\btrack\\libs\\libtracker.DLL\n",
      "[INFO][2024/02/15 11:30:41 AM] btrack (v0.5.0) library imported\n",
      "[INFO][2024/02/15 11:30:41 AM] Starting BayesianTracker session\n",
      "[INFO][2024/02/15 11:30:41 AM] Loading configuration file: C:\\Users\\RCORBYN\\OneDrive - University of Glasgow\\Desktop\\For paper\\20231114_Simona\\cell_config.json\n",
      "[INFO][2024/02/15 11:30:41 AM] Objects are of type: <class 'list'>\n",
      "[INFO][2024/02/15 11:30:41 AM] Starting tracking... \n",
      "[INFO][2024/02/15 11:30:41 AM] Update using: ['MOTION']\n",
      "[INFO][2024/02/15 11:30:41 AM] Tracking objects in frames 0 to 97 (of 97)...\n",
      "[INFO][2024/02/15 11:30:41 AM]  - Timing (Bayesian updates: 0.00ms, Linking: 0.00ms)\n",
      "[INFO][2024/02/15 11:30:41 AM]  - Probabilities (Link: 0.99986, Lost: 1.00000)\n",
      "[INFO][2024/02/15 11:30:41 AM] SUCCESS.\n",
      "[INFO][2024/02/15 11:30:41 AM]  - Found 768 tracks in 97 frames (in 0.0s)\n",
      "[INFO][2024/02/15 11:30:41 AM]  - Inserted 520 dummy objects to fill tracking gaps\n",
      "[INFO][2024/02/15 11:30:41 AM] Loading hypothesis model: cell_hypothesis\n",
      "[INFO][2024/02/15 11:30:41 AM] Calculating hypotheses (relax: True)...\n",
      "[INFO][2024/02/15 11:30:41 AM] Setting up constraints matrix for global optimisation...\n",
      "[INFO][2024/02/15 11:30:41 AM] Using GLPK options: {'tm_lim': 60000}...\n",
      "[INFO][2024/02/15 11:30:41 AM] Optimizing...\n",
      "[INFO][2024/02/15 11:30:41 AM] Optimization complete. (Solution: optimal)\n",
      "[INFO][2024/02/15 11:30:41 AM]  - Fates.FALSE_POSITIVE: 205 (of 768)\n",
      "[INFO][2024/02/15 11:30:41 AM]  - Fates.LINK: 355 (of 542)\n",
      "[INFO][2024/02/15 11:30:41 AM]  - Fates.DIVIDE: 21 (of 59)\n",
      "[INFO][2024/02/15 11:30:41 AM]  - Fates.INITIALIZE_BORDER: 16 (of 38)\n",
      "[INFO][2024/02/15 11:30:41 AM]  - Fates.INITIALIZE_FRONT: 35 (of 52)\n",
      "[INFO][2024/02/15 11:30:41 AM]  - Fates.INITIALIZE_LAZY: 115 (of 678)\n",
      "[INFO][2024/02/15 11:30:41 AM]  - Fates.TERMINATE_BORDER: 19 (of 35)\n",
      "[INFO][2024/02/15 11:30:41 AM]  - Fates.TERMINATE_BACK: 73 (of 104)\n",
      "[INFO][2024/02/15 11:30:41 AM]  - Fates.TERMINATE_LAZY: 95 (of 629)\n",
      "[INFO][2024/02/15 11:30:41 AM]  - TOTAL: 2905 hypotheses\n",
      "[INFO][2024/02/15 11:30:41 AM] Completed optimization with 413 tracks\n",
      "[INFO][2024/02/15 11:30:41 AM] Opening HDF file: C:\\Users\\RCORBYN\\OneDrive - University of Glasgow\\Desktop\\For paper\\20231114_Simona/tracks.h5...\n",
      "[INFO][2024/02/15 11:30:42 AM] Writing tracks/obj_type_1\n",
      "[WARNING][2024/02/15 11:30:42 AM] Removing tracks/obj_type_1.\n",
      "[INFO][2024/02/15 11:30:42 AM] Writing dummies/obj_type_1\n",
      "[INFO][2024/02/15 11:30:42 AM] Writing LBEP/obj_type_1\n",
      "[INFO][2024/02/15 11:30:42 AM] Writing fates/obj_type_1\n",
      "[INFO][2024/02/15 11:30:42 AM] Closing HDF file: C:\\Users\\RCORBYN\\OneDrive - University of Glasgow\\Desktop\\For paper\\20231114_Simona/tracks.h5\n",
      "[INFO][2024/02/15 11:30:42 AM] Starting tracking... \n",
      "[INFO][2024/02/15 11:30:42 AM] Update using: ['MOTION', 'VISUAL']\n",
      "[INFO][2024/02/15 11:30:42 AM] SUCCESS.\n",
      "[INFO][2024/02/15 11:30:42 AM]  - Found 413 tracks in 97 frames (in 0.0s)\n",
      "[INFO][2024/02/15 11:30:42 AM]  - Inserted 520 dummy objects to fill tracking gaps\n",
      "[INFO][2024/02/15 11:30:42 AM] Ending BayesianTracker session\n"
     ]
    }
   ],
   "source": [
    "stack_masks = np.array(raw_masks)\n",
    "print(stack_masks.shape)\n",
    "stack_masks = stack_masks[0, 0, :, :, :]\n",
    "\n",
    "script_folder = os.getcwd()\n",
    "configer_file = script_folder + '\\\\cell_config.json'\n",
    "\n",
    "# Find the tracks for the individual cells in the image stack. \n",
    "cell_tracks, properties, graph = find_Btracks(stack_masks, configer_file, script_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31b3144-ceb7-4db2-a452-e19f8f0a9bc6",
   "metadata": {},
   "source": [
    "## Cell 12\n",
    "----\n",
    "### Filter the tracks according to user-defined minimum track length\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fac97ffa-5043-41ba-8184-0db6c110348b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the tracks data into a pandas dataframe. \n",
    "data_arr = np.array(cell_tracks)\n",
    "df_data = pd.DataFrame({'Track': data_arr[:, 0].astype(int), 'Frame': data_arr[:, 1].astype(int), 'X_pos': data_arr[:, 2], 'Y_pos': data_arr[:, 3]})\n",
    "\n",
    "# Find the indicies which describe a change in the object track. \n",
    "index = particle_index(df_data)\n",
    "\n",
    "# Filter the tracks by the minimum track length. \n",
    "filtered_tracks, filtered_props = filter_tracks(df_data, pd.DataFrame(properties), min_tracks, index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbeb4d51-2779-4f14-a579-6615c61ad524",
   "metadata": {},
   "source": [
    "## Cell 13\n",
    "----\n",
    "### Calculate the shape features for all masks in the filtered tracks list. \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3d9e0cda-af42-486d-8181-6ccd23edb0f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 4466/4466 [00:41<00:00, 108.53it/s]\n"
     ]
    }
   ],
   "source": [
    "# Initialise variable. \n",
    "track_shapes_pd = pd.DataFrame()\n",
    "\n",
    "pixel_area = np.power(image_resolution, 2)\n",
    "\n",
    "# for all the frames contained in the filtered_tracks variable. \n",
    "for i in tqdm( range( len( filtered_tracks['Track'] ) ) ):\n",
    "    \n",
    "    # Extract the frame of interest. \n",
    "    image_to_analyse = np.array(stack_masks[filtered_tracks['Frame'][i], :, :])\n",
    "    \n",
    "    # Extract the [x,y] for the track central point (track point) . \n",
    "    y_loc = int(filtered_tracks['X_pos'][i])\n",
    "    x_loc = int(filtered_tracks['Y_pos'][i] )\n",
    "    \n",
    "    # Makle sure the track point is within the image boundry. \n",
    "    if x_loc > stack_masks.shape[2]: \n",
    "        x_loc = stack_masks.shape[2]-1\n",
    "    if y_loc > stack_masks.shape[1]:\n",
    "        y_loc = stack_masks.shape[1]-1\n",
    "    \n",
    "    # Find the pixel value at the track point.\n",
    "    image_value = image_to_analyse[ y_loc, x_loc ]\n",
    "    \n",
    "    # Ignore the analysis if the track point value is 0.\n",
    "    # This means the tracking has missed the cell mask. \n",
    "    if image_value == 0: \n",
    "        continue \n",
    "    else: \n",
    "        # Find all the values in the image with the same value as \n",
    "        # the track point. \n",
    "        find_mask = np.where(image_to_analyse == image_value)\n",
    "        \n",
    "        # Find the values needed to generate a square around the \n",
    "        # mask in question. \n",
    "        index = [np.min(find_mask[0]), np.max(find_mask[0]), \n",
    "                            np.min(find_mask[1]), np.max(find_mask[1])]\n",
    "\n",
    "        # If the cell mask is at the image boarder, ignore it. \n",
    "        if index[0] == 0 or index[2] == 0 or np.max(find_mask[0]) == image_to_analyse.shape[0] or np.max(find_mask[1]) == image_to_analyse.shape[1]:\n",
    "            continue \n",
    "\n",
    "        else: \n",
    "            # Correct the index value to allow 2 pixels between the \n",
    "            # cell mask and the image boarder. \n",
    "            # Needed to accurately find the perimeter of the cell mask. \n",
    "            index = correct_index(index, image_to_analyse)\n",
    "            \n",
    "            # Generate a sub image: a square around the mask in question. \n",
    "            sub_image = np.array(image_to_analyse[index[0]-2 : index[1]+2, index[2]-2 : index[3]+2])\n",
    "            \n",
    "            # Find the perimeter around the cell. \n",
    "            contour = get_contours(sub_image)\n",
    "            \n",
    "            # Find the area and perimeter of the cell mask in pixels. \n",
    "            area = len(find_mask[0])\n",
    "            perimeter = len(contour[:,0])\n",
    "            \n",
    "            # Find the major and minor axis of the cell mask. \n",
    "            # Needed to calculate eccentricity. \n",
    "            major_axis, minor_axis = find_shape_values(contour)\n",
    "            # Calcuate eccentricity. \n",
    "            eccent = np.sqrt(1 - (minor_axis / major_axis) )\n",
    "            \n",
    "            # Store all information into a dictionary. \n",
    "            cell_shape_dict = {'Track': [filtered_tracks['Track'][i]],\n",
    "                   'Frame': [filtered_tracks['Frame'][i]],\n",
    "                    'Mask Number': [image_value],\n",
    "                   'X_pos': [filtered_tracks['Y_pos'][i]], \n",
    "                   'Y_pos': [filtered_tracks['X_pos'][i]], \n",
    "                   'Area (microns Squared)': [area * pixel_area], \n",
    "                   'Perimeter (microns)': [perimeter * image_resolution], \n",
    "                   'Major Axis (microns)': [major_axis * image_resolution], \n",
    "                   'Minor Axis (microns)': [minor_axis * image_resolution], \n",
    "                   'eccentricity': [eccent]}\n",
    "            \n",
    "            # Convert dictionary to dataframe\n",
    "            temp_df = pd.DataFrame(cell_shape_dict)\n",
    "            \n",
    "            # Append all information into a local variable. \n",
    "            track_shapes_pd = pd.concat([track_shapes_pd, temp_df])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e84aef5-1643-48a4-b734-19a15ac03a6b",
   "metadata": {},
   "source": [
    "## Cell 14\n",
    "----\n",
    "## Save the segmentation mask data. \n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3496dc-a4c6-4fd4-96a6-558eaf389592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the folder path from the file containing \n",
    "# the segmentation mask stack.\n",
    "save_path = os.path.dirname(mask_file_name)\n",
    "\n",
    "# Save the analysis to the same folder as the segmentation mask file. \n",
    "track_shapes_pd.to_csv(save_path + '\\\\' + 'cellpose_mask_shape_analysis.csv',\n",
    "                       index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:cellpose_and_tracking_gpu]",
   "language": "python",
   "name": "conda-env-cellpose_and_tracking_gpu-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
