{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e74886d-5c18-4003-91ce-8e4f4a759d4b",
   "metadata": {},
   "source": [
    "---\n",
    "# Cellpose segmentation and BTrack tracking\n",
    "---\n",
    "\n",
    "Author: Ryan Corbyn,   \n",
    "Date: 06/01/2023.\n",
    "\n",
    "-----\n",
    "#### Script Description:  \n",
    "This program is capable of segmenting and tracking cells from a phase-contrast time-lapse data.  \n",
    "\n",
    "The script can handle the time-lapse data being in the form of either: \n",
    "1. A folder containing the time-lapse images as individual single frames (In this case the naming convention must be carefully chosen so that the images can be read in time-order. \n",
    "2. A single .tif file that contains all of the time-lapse images saved as a 3D image, with the image shape being: (time, x, y).\n",
    "\n",
    "**A single stack image must be saved as .tif file type.**\n",
    "\n",
    "The user is required to input the format of their imaging files at the start of the script. \n",
    "\n",
    "Once the image location has been selected, the image data is read into the program and the cells in the images are segmented using the cellpose library: https://cellpose.readthedocs.io/en/latest/index.html. The script is designed so that the user can select either one of the default cellpose segmentation models, or a bespoke retrained model can be used for cell segmentation. If using a retrained model, it may be required to first load the script into the cellpose library through the GUI:\n",
    "https://cellpose.readthedocs.io/en/latest/models.html\n",
    "\n",
    "Once the cells have been segmented, the segmenation masks are saved to create a cell mask image stack. This mask-stack is then used to capture cell movement using the BTrack library: https://btrack.readthedocs.io/en/latest/. Th BTrack library has some level of adaptability to improve the quality of the cell tracks generated by refining:\n",
    "1) The number of frames that an object is tracked over. \n",
    "2) The number of permissable frames that an object may not be detected. \n",
    "3) The number of pixels away from the previous frame that an object is allowed to move before it is considered a new object. \n",
    "\n",
    "Once the tracking has been complete, this script allows the tracks to be filtered to only include objects tracked for longer than a user-defined minimum number of frames. This is useful to exclude objects/cells that only appear in the field of view for a few frames within the time-lapse measurement from the analysis. \n",
    "\n",
    "From the output of defining the tracks of the cells, the total displacement of the object and its trajectory are calculated. \n",
    "The results from all this analysis is saved into an analysis folder that is generated within the same folder that contains the raw image data.  \n",
    "\n",
    "\n",
    "-----\n",
    "#### Required inputs from the User:  \n",
    "This script requires that the user manually include: \n",
    "1. The total measurement time in minutes - Cell 2.\n",
    "2. The Image resolution used when recording the images - Cell 2. \n",
    "3. The minimum number of frames an object must be tracked for to be included in the analysis - Cell 2. \n",
    "4. How the image data is stored, either:\n",
    "    - A single time-lapse stack image ('single_file') - Cell 2. \n",
    "    - A series of single frame .tif files saved within a folder ('folder_of_images') - Cell 2. \n",
    "5. The directory that houses the experiment images - Cell 11. \n",
    "6. The segmentation model for the analysis - Cell 12.\n",
    "-------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d4faad-f975-4357-927e-69aaa4ea1f35",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Cell 1\n",
    "---\n",
    "### Import the dependancies for the script\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f077e98-5ce1-4d00-84ab-d8eb4504d59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import cellpose and other dependancies\n",
    "from cellpose import models, io, core, plot \n",
    "import btrack\n",
    "import napari\n",
    "\n",
    "# Import libraries for data analysis\n",
    "import numpy as np \n",
    "from PIL import Image\n",
    "import tifffile as tf\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Import dependancies for user interface/input\n",
    "from tqdm import tqdm\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0724ed5a-aaa9-4a50-86d8-6942f9c7a4bd",
   "metadata": {},
   "source": [
    "## Cell 2\n",
    "---\n",
    "### User inputs\n",
    "---\n",
    "\n",
    "In the following cell, the user needs to input: \n",
    "1) The total time of the experiment in minuntes. \n",
    "2) The resolution of the images to be analysed. \n",
    "3) The minimum track length for an object to be included in the analysis.\n",
    "4) How the time-lapse data is stored, either as:\n",
    "    - A series of individual images within a folder: 'folder_of_images'\n",
    "    - A single stack image containing all the time-lapse data: 'single_file'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995a5d9a-53f8-40f3-8fa0-8f91437b74d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_time = 16*30 # total measurement time in minutes. \n",
    "image_resolution = 0.635 # microns per pixel. \n",
    "\n",
    "# select the minimum number of tracks that an object must be tracked for. \n",
    "min_tracks = 3\n",
    "\n",
    "# Select the input type for the experiment data. \n",
    "# input_type = 'folder_of_images'\n",
    "input_type = 'single_file'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ef6668-02dd-4c64-8412-292fce8d6638",
   "metadata": {},
   "source": [
    "### Cell 3 \n",
    "- A Function to get all the file names from the imaging folder defined below.\n",
    "- Returns a list of image file names. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b5e3fd-ff14-4269-b325-723ea5138980",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_file_names(folder_path): \n",
    "    '''Get all the file names for .tif files in a folder.'''\n",
    "    \n",
    "    # initalised \n",
    "    list_of_files = []\n",
    "    # Loop through all files and folders within the directory\n",
    "    # specified in \"folder_path\"\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        # For all the file names. \n",
    "        for file in files:\n",
    "            # If the file type matches one of the following extensions: \n",
    "            # Save the file name. \n",
    "            if file[-4:] == '.jpg' or file[-4:] == '.tif' or file[-4:] == '.png' or file[-4:] == '.TIF':\n",
    "                list_of_files.append(os.path.join(file))\n",
    "                \n",
    "    return(list_of_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9446fce0-f786-4b93-8780-5645dae3faa9",
   "metadata": {},
   "source": [
    "### Cell 4\n",
    "- A fuction that runs the cellpose analysis on the image frame sent to the function. \n",
    "- Returns the cell masks generated by cellpose. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd09853-c164-403d-9a22-4cafefd7a18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cellpose_analysis(image, channel, cellpose_model):\n",
    "    '''A method to analyse the images in a stack using the \n",
    "    cellpose algorithm.'''\n",
    "    \n",
    "    masks, flows, styles = cellpose_model.eval(image, diameter=None, channels = channel)\n",
    "    \n",
    "    return(masks, flows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8a1537-ad0d-4e90-ac87-fdd217ce6f43",
   "metadata": {},
   "source": [
    "### Cell 5\n",
    "- A function to perform the cell tracking on the cellpose masks using the BTracks Algorithm. \n",
    "- Returns a python dictionary of the cell tracks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9dcefd-cd6d-4cc0-a723-187b18c254f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_Btracks(image_masks, configer_file, script_fold):\n",
    "    '''A method to find the tracks from the cellpose masks\n",
    "    generated from the image stack. \n",
    "    this method makes use of the trackpy package.'''\n",
    "    \n",
    "    FEATURES = [\n",
    "      \"area\",\n",
    "      \"major_axis_length\",\n",
    "      \"minor_axis_length\",\n",
    "       \"eccentricity\",\n",
    "      \"solidity\",\n",
    "                ]\n",
    "\n",
    "    objects = btrack.utils.segmentation_to_objects(image_masks, properties=tuple(FEATURES))\n",
    "    \n",
    "    with btrack.BayesianTracker() as tracker:\n",
    "        # configure the tracker using a config file\n",
    "        tracker.configure_from_file(configer_file)\n",
    "\n",
    "        tracker.features = FEATURES\n",
    "\n",
    "        # append the objects to be tracked\n",
    "        tracker.append(objects) \n",
    "\n",
    "        # set the volume (Z axis volume is set very large for 2D data)\n",
    "        tracker.volume=((0, 2000), (0, 2000), (-1e5, 1e5))\n",
    "\n",
    "        # track them (in interactive mode)\n",
    "        tracker.track(step_size=100)\n",
    "\n",
    "        # generate hypotheses and run the global optimizer\n",
    "        tracker.optimize()\n",
    "\n",
    "        # store the data in an HDF5 file\n",
    "        tracker.export(script_fold + '\\\\tracks.h5', obj_type='obj_type_1')\n",
    "\n",
    "        # get the tracks as a python list\n",
    "        tracks = tracker.tracks#(tracking_updates=TRACKING_UPDATES)\n",
    "\n",
    "        # get the data in a format for napari\n",
    "        data, properties, graph = tracker.to_napari(ndim=2)\n",
    "    \n",
    "    return(data, properties, graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817d2429-798c-481b-9073-ea36a6930eda",
   "metadata": {},
   "source": [
    "### Cell 6\n",
    "- A function to filter the tracks by the minimum track length defined in cell 2. \n",
    "- Returns a pandas dataframe of the filtered tracks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012541e1-cf9c-4c7a-a56b-4ee36d6cfd55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_tracks(tracks, props, min_track_len, indicies):\n",
    "    '''Filter the tracks variable to only contain tracks longer than a \n",
    "    specified minimum (track_min). The resulting pandas array is then \n",
    "    sorted by object order.'''\n",
    "    \n",
    "    \n",
    "    filtered_tracks = pd.DataFrame()\n",
    "    filtered_props = pd.DataFrame()\n",
    "    \n",
    "    for i in range(indicies.shape[0]):\n",
    "        if indicies[i][1] - indicies[i][0] > min_track_len: \n",
    "            single_track = pd.DataFrame(tracks.iloc[indicies[i][0]: indicies[i][1]])\n",
    "            single_props = pd.DataFrame( props.iloc[indicies[i][0]: indicies[i][1]] )\n",
    "            \n",
    "            filtered_tracks = pd.concat([filtered_tracks, single_track], ignore_index = True)\n",
    "            filtered_props = pd.concat([filtered_props, single_props], ignore_index = True)\n",
    "        \n",
    "    return(filtered_tracks, filtered_props)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "449d54de-8ec9-4ec3-aa7f-646665287597",
   "metadata": {},
   "source": [
    "### Cell 7\n",
    "- A function to find the indicies at which the cell track ID changes within the cell tracking dataframe. \n",
    "- Returns an numpy array of the points of Track ID changes within the cell tracking dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872cc4d1-d3bf-4ae0-8fe0-f961d36e88fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def particle_index(tracks):\n",
    "    '''Find the indicies where the particle object in the \n",
    "    sorted_tracks variable changes. '''\n",
    "    \n",
    "    # Set the initial particle value\n",
    "    particle = tracks['Track'].iloc[0]\n",
    "    # generate the index_score variable. \n",
    "    index_score = [0]\n",
    "\n",
    "    # Loop to find the indicies in which the particle value changes. \n",
    "    for i in range(tracks.shape[0]):\n",
    "        if tracks['Track'].iloc[i] != particle:\n",
    "            index_score.append(i-1)\n",
    "            particle = tracks['Track'].iloc[i]\n",
    "            index_score.append(i)\n",
    "\n",
    "    # grab last i value. \n",
    "    index_score.append(i)\n",
    "    \n",
    "    # Convert index score to a 2D numpy array. \n",
    "    index_score = np.reshape(index_score, [int(len(index_score)/2), 2])\n",
    "    \n",
    "    return(index_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede4f7c1-33bb-4ecf-bca1-d5ff5584f433",
   "metadata": {},
   "source": [
    "### Cell 8\n",
    "- A function to measure the displacement a cell travels throughout the time-lapse measurement and it's trajectory (direction of travel). \n",
    "- Returns: \n",
    "    1. A list of distances travelled by all tracked objects.\n",
    "    2. A list of the trajectories for the tracked cells. \n",
    "    \n",
    "Note: Displacement is defined as the difference in the x, y co-ordinates between the initial start position and the final end position of the cell track. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c491b1-9433-4586-8924-8c2692bc7381",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_traj_and_displacement(tracks, indicies): \n",
    "    '''Find the trajectory and the distance moved for each of the \n",
    "    particles defined by the trackpy algorithm. '''\n",
    "    \n",
    "    # initialise variable. \n",
    "    distance_moved = []\n",
    "    trajectory = []\n",
    "    \n",
    "    # for all the tracks identified\n",
    "    for l in range(indicies.shape[0]):\n",
    "        x_distance = tracks['X_pos'][indicies[l, 1]] - tracks['X_pos'][indicies[l, 0]] \n",
    "        y_distance = tracks['Y_pos'][indicies[l, 1]] - tracks['Y_pos'][indicies[l, 0]] \n",
    "        \n",
    "        # calculate the total distance moved and trajectory. \n",
    "        distance_moved.append( np.sqrt( np.power(x_distance, 2) + np.power(y_distance, 2) ) )\n",
    "        trajectory.append( np.arctan2(y_distance, x_distance) * 180/np.pi)\n",
    "    \n",
    "    return(distance_moved, trajectory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "265c8ef7-5692-4664-a65c-8f70c399bee3",
   "metadata": {},
   "source": [
    "### Cell 9\n",
    "- A function to calculate the total distance travelled and the speed of cell movement. \n",
    "- Returns a numpy array of the distance travelled by the cells, and their speed of movement. \n",
    "\n",
    "Note: Distance is defined as the total distance moved by the cell through all frames, this is distinct from displacement, as this includes all points of cell movement between the start and end of a cell track.  \n",
    "Speed is defined as distance travelled / length of time tracked. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd4778c-3e8e-4e00-bcaf-f49f85f9f2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_and_speed(tracks, ind, res, time_frame):\n",
    "    '''Calculate the distance and speed that the cells \n",
    "    travel. '''\n",
    "\n",
    "    all_rs_distance = []\n",
    "    speed = []\n",
    "\n",
    "    for i in range(index_2.shape[0]):\n",
    "        x = np.array( tracks['X_pos'][ind[i][0]:ind[i][1]] )\n",
    "        y = np.array( tracks['Y_pos'][ind[i][0]:ind[i][1]] )\n",
    "        rs_distance = 0\n",
    "\n",
    "        for j in range(x.shape[0]-1):\n",
    "            # travel = SQRT ( (Delta X)^2 + (Delta Y)^2 ) \n",
    "            travel = np.sqrt( np.power( (x[j] - x[j+1]), 2 ) +  np.power( (y[j] - y[j+1]), 2 ) )\n",
    "            rs_distance = rs_distance + travel\n",
    "\n",
    "        all_rs_distance.append(rs_distance*res)\n",
    "        \n",
    "        speed.append( np.array(all_rs_distance[i]) / (time_frame * x.shape[0]) )\n",
    "\n",
    "    all_rs_distance = np.round(np.array(all_rs_distance), 3)\n",
    "\n",
    "    speed = np.round( speed, 3) \n",
    "    \n",
    "    return(all_rs_distance, speed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bb3c08-53e3-4fb5-b9e2-e35c3f4114f7",
   "metadata": {},
   "source": [
    "### Cell 10 \n",
    "- A function to calculate the directionality of cell movement. \n",
    "- Returns an numpy array of directionality information for all cell tracks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8078e62-6d1d-42ea-8134-64f9734cee1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def directionality_calc(distance_travelled, displace):\n",
    "    '''Calcualted the directness of a cells motion. This is a very \n",
    "    simple calculation and is taken from ibidi Chemotaxis tool manual. \n",
    "    as of 12/01/2023, this information can be found at the following URL: \n",
    "    https://ibidi.com/img/cms/products/software/chemotaxis_tool/Manual_ChemotaxisTool_2_0_eng.pdf\n",
    "    on page 15. '''\n",
    "    \n",
    "    direction = np.array(displace)/np.array(distance_travelled)\n",
    "    \n",
    "    return(direction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07771ff-0d52-4b36-b773-be2382c96d78",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Cell 11\n",
    "---\n",
    "### Select the folder containing the raw images \n",
    "---\n",
    "Running the following cell generates a file-dialogue box to select the folder containing the images to analyse. \n",
    "\n",
    "#### Important Note:  \n",
    "This script is capable of taking in a user input of either: \n",
    "1. A folder containing lots of single frames from a time-lapse experiment\n",
    "2. A Single file containing the whole time-lapse image stack as a .tif file. \n",
    "\n",
    "Both options are included below, the user is required to select which is appropriate for their analysis.  \n",
    "- It is recommended to comment out the lines you do not need. \n",
    "- A block-comment can be performed (on windows) by selecting the code you wish to comment/uncomment and pushing \"ctrl + /\" at the same time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf27b75-58f3-42ef-9d41-595431d27367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates dialogue to ask directory\n",
    "# Get the folder containing the image stack. \n",
    "root = tk.Tk()\n",
    "root.attributes(\"-topmost\", True)\n",
    "root.withdraw() # Stops a second window opening\n",
    "\n",
    "if input_type == 'folder_of_images': \n",
    "    ################\n",
    "    # For a Folder containing lots of images.\n",
    "    # Select the folder containing images. \n",
    "    SourceFolder = filedialog.askdirectory(title = 'Select Folder Containing images')\n",
    "    # Get all .tif files in a folder. \n",
    "    file_list = get_image_file_names(SourceFolder)\n",
    "    ################\n",
    "    \n",
    "else:\n",
    "    #################\n",
    "    ## For Selecting a single time-lapse image as a .tif.\n",
    "    # Select the time-lapse image file. \n",
    "    SourceFolder = filedialog.askopenfilename(title = 'Select time-lapse image file')\n",
    "    # Convert \n",
    "    file_list = SourceFolder \n",
    "\n",
    "##########\n",
    "print(SourceFolder, len(file_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffa390be-0d74-4de3-a0a5-676561312ac8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Cell 12\n",
    "--- \n",
    "### Select the Cellpose model\n",
    "---\n",
    "Two options here: \n",
    "1. Can select a pre-defined cellpose model from the file directory.\n",
    "2. Can choose one of the pre-existing cellpose models. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60483068-1716-4a76-acd9-5b231422f60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select user defined segmentation model. \n",
    "root = tk.Tk()\n",
    "root.withdraw()\n",
    "model_dir = tk.filedialog.askopenfilename(title = \"Select Cellpose model\")\n",
    "\n",
    "# Output the names of all the pre-trained segmentation models that come as standard with cellpose. \n",
    "# models.MODEL_NAMES \n",
    "\n",
    "# # Select the pre-defined segmentation model.\n",
    "# model_dir = 'livecell'\n",
    "\n",
    "print(model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d309ed-fa0e-47ea-86e9-cfdbd12daa3e",
   "metadata": {},
   "source": [
    "## Cell 14\n",
    "--- \n",
    "### Run the cellpose segmentation on all the images in the folder. \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49886ae3-f514-47f2-8d0f-76be616b3bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the channels for grey-scale images. \n",
    "channel = [0, 0]\n",
    "# initialise the variable. \n",
    "image_stack = []\n",
    "stack_masks = []\n",
    "\n",
    "# If the input was a single time-lapse image stack.  \n",
    "if input_type == 'single_file': \n",
    "    # Image-stack already exists. \n",
    "    image_stack = tf.imread(file_list)\n",
    "    loop_counter = image_stack.shape[0]\n",
    "else:\n",
    "    loop_counter = len(file_list)\n",
    "\n",
    "# Using a user-defined model for analysis. \n",
    "model = models.CellposeModel(model_type = model_dir)\n",
    "\n",
    "for j in tqdm( range( loop_counter ) ): \n",
    "    if input_type == 'single_file': \n",
    "        # Get a single frame from the image_stack. \n",
    "        phase_image_arr = np.array(image_stack[j, ...])\n",
    "    else: \n",
    "        # Select a single file name. \n",
    "        image_file = file_list[j]\n",
    "        # Extract the image stack data using the tifffile.  \n",
    "        phase_image_stack = Image.open(SourceFolder + '//' + image_file)\n",
    "        phase_image_arr = np.array(phase_image_stack)\n",
    "\n",
    "        # # Create an image stack. \n",
    "        image_stack.append(phase_image_arr)\n",
    "        \n",
    "    # Get the mask and the flow from the selected image. \n",
    "    masks, flow = get_cellpose_analysis(phase_image_arr, channel, model)\n",
    "    # Save the image masks. \n",
    "    stack_masks.append(masks)\n",
    "\n",
    "stack_masks = np.array(stack_masks)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408f4806-108f-4123-99f2-158981b35c36",
   "metadata": {},
   "source": [
    "## Cell 15\n",
    "--- \n",
    "### Use Btracks to track the cell masks\n",
    "--- \n",
    "Note: This results in tracking information being displayed in a pink. This is a normal part of running the Btrack algorithm, and not a error message. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7bb8c3-3e4f-452f-8b9f-b9e7a486ed4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack_masks = np.array(stack_masks)\n",
    "\n",
    "script_folder = os.getcwd()\n",
    "configer_file = script_folder + '\\\\cell_config.json'\n",
    "# Find the tracks for the individual cells in the image stack. \n",
    "cell_tracks, properties, graph = find_Btracks(stack_masks, configer_file, script_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f37ac4-6056-49ec-a77e-357d4ed6b1ec",
   "metadata": {},
   "source": [
    "## Cell 16\n",
    "---\n",
    "### Analyse the results of the BTracks algorithm\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4623b199-e32f-4c0c-9bb6-871850387d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the tracks data into a pandas dataframe. \n",
    "data_arr = np.array(cell_tracks)\n",
    "df_data = pd.DataFrame({'Track': data_arr[:, 0].astype(int), 'Frame': data_arr[:, 1].astype(int), 'X_pos': data_arr[:, 2], 'Y_pos': data_arr[:, 3]})\n",
    "\n",
    "# Find the indicies which describe a change in the object track. \n",
    "index = particle_index(df_data)\n",
    "\n",
    "# Filter the tracks by the minimum track length. \n",
    "filtered_tracks, filtered_props = filter_tracks(df_data, pd.DataFrame(properties), min_tracks, index)\n",
    "\n",
    "# Find the indicies which describe a change in the object track. \n",
    "index_2 = particle_index(filtered_tracks)\n",
    "\n",
    "# Find the total displacement of the cell and it's trajectory for all tracks in the stack. \n",
    "displacement, trajectory = get_traj_and_displacement(filtered_tracks, index_2)\n",
    "\n",
    "time_per_frame = experiment_time / stack_masks.shape[0]\n",
    "\n",
    "distance, speed = distance_and_speed(filtered_tracks, index_2, image_resolution, time_per_frame)\n",
    "directionality = directionality_calc(distance, displacement)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2066a341-1740-4d7c-afc7-6b146c1fecaf",
   "metadata": {},
   "source": [
    "## Cell 17\n",
    "---\n",
    "### View the total displacement and trajectory in Napari\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4950c5-193c-4220-a9e1-570d29332fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a napari window. \n",
    "viewer = napari.Viewer()\n",
    "\n",
    "# Add the GFP masks to the napari viewer. \n",
    "viewer.add_image( np.array(image_stack) )\n",
    "# Add the tracks to the napari viewer. \n",
    "viewer.add_labels(stack_masks)\n",
    "# Add the tracks to the napari viewer. \n",
    "graph = {}\n",
    "viewer.add_tracks(filtered_tracks, properties=dict(filtered_props), graph=graph)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "961ecef5-d5b1-42c4-8d0e-36d2f9d49178",
   "metadata": {},
   "source": [
    "## Cell 18\n",
    "---\n",
    "### Plot the Trajectory and Total Distance on a polar plot\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f56fbe-3e8a-4bfa-b2a9-6de08f148109",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot the resultant analysis on a polar plot. \n",
    "fig, ax = plot.subplots(subplot_kw={'projection': 'polar'})\n",
    "plot.polar(trajectory, np.array(displacement)*image_resolution, 'x', color = 'r')\n",
    "plot.title('Cell trajectory (degrees) and Total Distance Traveled (microns)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9e896b-0bbc-4b34-89b1-a4abbc436982",
   "metadata": {},
   "source": [
    "## Cell 19\n",
    "---\n",
    "### Set up the save folders and save the data. \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "789d65da-4ea9-45bc-bf89-2140bc1993bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Save path.\n",
    "save_path = SourceFolder + '//Cellpose_and_BTrack_analysis'\n",
    "# Create the foilder if it does not exist.\n",
    "if os.path.exists(save_path) == False:\n",
    "    os.mkdir(save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3750a6a-c7b3-4a8f-a739-86f910a1bc45",
   "metadata": {},
   "source": [
    "## Cell 20\n",
    "----- \n",
    "### Save the track information and the track analysis as .csv files and save the Polar plot as a .pdf.\n",
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe245ed6-752e-4455-bc41-c3932f807c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pandas data frame for total distance and trajectory.\n",
    "dict_track_info = {'Track': np.linspace(1, index_2.shape[0], index_2.shape[0]).astype(int), \n",
    "                  'Displacement (Microns)': np.array(displacement) * image_resolution, \n",
    "                  'Trajectory (Degrees)': trajectory, \n",
    "                  'Total Distance travelled (Microns)': distance,\n",
    "                  'Speed (Microns / Minutes)': speed, \n",
    "                  'Directionality': directionality}\n",
    "\n",
    "# Generate a pandas dataframe of the tracking data. \n",
    "track_info = pd.DataFrame(dict_track_info)\n",
    "\n",
    "# Save the tracks to csv. \n",
    "filtered_tracks.to_csv(save_path + '\\\\' + 'Tracks_data_(min_track_length_' + str(min_tracks) + \n",
    "                       '_tracks).csv', index=False)\n",
    "\n",
    "# Save the track analysis to csv. \n",
    "track_info.to_csv(save_path + '\\\\' + 'Analysis_of_Tracks_data_(min_track_length_' + str(min_tracks) + \n",
    "                       '_tracks).csv', index=False)\n",
    "\n",
    "# Save the polar plot. \n",
    "fig.savefig(save_path + '\\\\Tracks_Polar_Plot.pdf', bbox_inches = 'tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81bff95-bcaa-4110-832c-8a059ebfa690",
   "metadata": {},
   "source": [
    "## Cell 21\n",
    "--- \n",
    "### Save the segmenation mask as individual .tif files.  \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4bdbe7-49b4-4945-a12a-44a690d28994",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the masks as individual frames. \n",
    "save_mask_path = SourceFolder + '//cellpose_mask'\n",
    "if os.path.exists(save_mask_path) == False:\n",
    "    os.mkdir(save_mask_path)\n",
    "\n",
    "for i in range(len(file_list)):\n",
    "    save_file_name = file_list[i]\n",
    "    im = stack_masks[i]\n",
    "    tf.imwrite(save_mask_path + '\\\\' + save_file_name[0:-4] + \"_cellpose_masks.tif\", \n",
    "         im)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e175a64e-8965-4273-98b2-85bd00c9d6c5",
   "metadata": {},
   "source": [
    "## Cell 22\n",
    "---\n",
    "### Save the images as a stack\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5b15bd-a0ca-4231-ae26-b8598dd9f2d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the image stack as a .tif\n",
    "tf.imwrite(save_path + '\\\\' + image_file[0:11] + \"_image_stack.tif\", \n",
    "         image_stack)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9493a2ab-2782-4fc7-aa98-e149e5cf530b",
   "metadata": {},
   "source": [
    "## Cell 23\n",
    "---\n",
    "### Save the segmenation mask as a .tif stack.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1613ffe-f62e-4dcd-ae1c-73aee4e43013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the masks as a .tif file. \n",
    "tf.imwrite(save_path + '\\\\' + image_file[0:11] + \"_cellpose_masks.tif\", \n",
    "         stack_masks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
